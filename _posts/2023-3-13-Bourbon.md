---
title: 'Bourbon'
date: 2023-3-11
permalink: /posts/2023/03/blog-post-Bournbon/
tags:
  - Learned Index
  - LSM-tree
  - KV Store
---

# From WiscKey to Bourbon: A Learned Index for Log-Structured Merge Trees（论文阅读理解）

## 一. Introduction

主要的一个设计点和出发的思路就是要在LSM-tree KV上使用learned Index，由标题可以明显的得出，且是结合了WiscKey的Key-Value分离的一个思路，两个点结合在一起使用。  

作者主要描述了Learned Index的优势：避免了二分搜索的搜索路径代价，基于分段线性回归的机器学习的方式，可以快速定位Key所在的位置和偏移的错误区间。  

作者表示，Learned Index同样适用于LSM-tree，并通过实验分析，并给出设计的一些原则。  

## 二. Background

第一  介绍Level DB的读路径:    

①搜索SST文件(逐层搜索,这个可以通过索引进行二分搜索,得到对应的SST文件,除L0外,每层只需要读取一个SST即可)  

② 加载Index Block和Filter Block,在SST内部进行搜索,并通过Filter判断Key是否存在。  

③在Index block搜索得到对应的data block位置  

④通过布隆过滤器，确认是否有该Key存在（布隆过滤器并不是绝对准确的）  

⑤加载Index Block处得到的Data Block  

⑥在Data Block中进行二分搜索，得到Key的位置  

⑦读取对应的Value  

注意的是，图中（b）部分，WiscKey采用KEY-Value分离的方式，Key后面存指针。这样可以减小写放大，Compaction的时候的开销比较小。（不过这是一种权衡，Key-Value分离也有不利的场景）。  

另外需要注意的一点是，作者将L0 L1等数据比较新的数据层称之为高层，Ln等数据层称之为底层。  

​
<img src="../../Yemaoxin.github.io/images/2023.3.blog/Bourbon-1.png" alt="图片alt" title="图片title">

LevelDB的读路径，WiscKey与之区别只在于最后第七步的Read Value
第二 优化LSMs中的Lookup搜索
由于每次搜索都需要逐层向下搜索，每个SSTable文件还需要读取许多block，才能最终找到，所以对于LSM tree的搜索优化是有意义的。
目前有的对读的优化，是通过Learned Index，通过线性模型，训练，输入一个Key值，给出这个Key所在的位置。
这样避免了复杂的搜索流程，可以在O（1）时间内得到。
但是目前Learned index都是在B-Trees上的，Learned Index是否适用于LSM tree？
这是作者的困惑，所以作者提出几个问题，并通过实验来验证。Learned index是不支持更新的，每次新的数据变化，需要重新训练模型。而LSM-tree又是写密集的工作流，Learned Index是否适用于LSM tree？
Can learned indexes for LSMs make lookups faster? If yes, under what scenarios? 
How to realize the benefits of learned indexes while supporting writes for which LSMs are optimized?
## 三、LSMs与Learned Index的适配性
这个部分可以说是作者主要的出力点，这个部分的论文写的很好。
研究在什么场景下learned index有效果？然后给出自己的推测，用实验去验证自己的推测。
1. Learned Index的有利场景 
根据下图可以得到FindFiles +LoadIB+FB+SearchIB+SearchFB是Index部分，这部分时间在不同设备上的占比不一样。优化Index的话可以取得减少延迟。根据四种设备上的延迟还有占用比例，作者认为当数据Cached在内存中的时候，优化Index能够减少latency，取得比较大的优化倍数。
对于快速设备如图中最后一条数据Optane上的情况，优化index也能优化Look的Latency。
​<img src="../../Yemaoxin.github.io/images/2023.3.blog/Bourbon-2.png" alt="图片alt" title="图片title">


2、写场景下的Learned Index
首先对于Learned Index对于读过程的优化已经有比较多的论文说明了，但是主要的一个缺陷就是Learned Index不支持插入和更新，这样会破坏原有训练好的数据分布。这就需要重新训练。（不过其实对于深层的SSTable而言，SST是不可变的，只有在Compaction的时候才会重写，就这一点来说的话，其实是比较合适用于Learned Index），这一点与b-tree不一样，作者同样描述了这一点）。
也就是说，LSM的更新数据是在内存或者在High level中的，而底层存在大量的稳定数据。对于底层部分的数据读，使用Learned Index是可以取得比较好的结果的，相反，对于high level 的SST的话，意义就不大。
接下来，作者通过实验，给出LSM Learned Index的设计原则。
SSTables的lifetime
​
<img src="../../Yemaoxin.github.io/images/2023.3.blog/Bourbon-3.png" alt="图片alt" title="图片title">

对于不同层来说，可以看到底层Level的平均lifetime比高层要高，验证了作者的想法。
对于write percentage，随着写比例的增加，所有层的leftime都下降，但是high level的lifetime降低到10s的量级，过于低了。low level中仍然有100-1000s。
另外对于L1层，（b）可以看出来，CDF中存在两个点：一部分数据的寿命很短，但跨过那个时间点之后，剩下的数据寿命又会相对长一些。（c）图一样可以看出来。
因此作者给出两个设计原则：
倾向于在lower level进行SSTs 文件的学习
在学习文件前，等待一个小时间。主要是L1处明显，等待一个小时间，让短寿命的SSTs die。避免模型还没训练出来，SSTs就被删除了。不会浪费计算资源
在不同层上的Internal Lookup操作
虽然已经从前一个实验得出了，在high level的SSTables文件的寿命比较短，有的才几秒钟，但是仍然要分析，因为所有的查询都是从上层开始的。
​<img src="../../Yemaoxin.github.io/images/2023.3.blog/Bourbon-4.png" alt="图片alt" title="图片title">


图4（a）部分展示了在随机load的情况下的每个文件的平均Internal  lookup次数，（b）展示了在顺序load的情况下的情况。
可以看到1. L0等high level的搜索次数是最多的，2. L0等high level的失败搜索次数是最多的（数据大部分落到lower level） 3. L4的成功搜索次数最多。 4. Zipfan的数据分布情况下，L0的搜索次数最多。（相对集中的某一部分数据，经常被写和读，成为最新的数据，会集中在数据high level）。
顺序load的参考意义不大。此外，随着写比例的提升，lookup的次数都会下降。
从以上，作者总结另外两条原则：
不能够忽视higher level的文件
需要能够识别workload和data的情况。
Lifetime of levels
由于整个Level的SSTables有序，从而可以对整个Level进行学习，提供一个key，得到对应的SSTable和在SSTable内的偏移，这叫Level Learning。另一种是对文件进行学习，对某一个SSTables，给出一个key，模型返回在SSTables内的偏移。这叫File Learning。
作者同样实现了Level Learning，但是只是作为Bourbon的一个配置项，不作为主要的研究。
由于一个Level内只要有一个文件发生变化，那么Level的生命就结束了，就必须要重新训练，所以从这个角度来说，Level的生命取决于时间最短的SSTables的lifetime。
可以得出结论，L1等higher Level的文件修改次数比较多，也就是说，L1的Level Lifetime比较短。
L4的LevelLifetime会长一些，但是当write percentage上升以后，导致L4的Lifetime也会下降，降到10秒级别，每训练一次Level Learning，消耗很大，对于LifeTime比较短的level 就没有必要做了。
由此得出结论：
在write heavy的workloads上不要使用level learning。
1. Bourbon 设计
## 基于WiscKey设计
4.1 Learning the Data
作者使用的机器学习模型是分段线性回归(Piecewise Linear Regression,PLR)
使用的算法是Greedy-PLR 算法。其他的类似RMI、PGM Index、splines等算法也许也有效果，作者不做进一步考虑这些对比。
4.2 支持可变size的Values
由于使用了键值分离，在key后面跟的是一个指针，所以指针的大小是固定的。
所以是有利于Learned Index的。通过通过模型计算出key所在的Dpos之后，直接乘以每个项的长度。从而模型就可以得到简化。模型只与SSTables文件内的key的顺序和分布有关系，与Value的变长没有关系。
所以就这个点来说，Key-Value分离和Learned Index是有利结合的。
4.3 Level learning vs. File learning
​
<img src="../../Yemaoxin.github.io/images/2023.3.blog/Bourbon-5.png" alt="图片alt" title="图片title">

根据Table1，可以得出，对于对于write heavy的workload，Level model起到的作用很小，仅有1.5%的Lookup路径使用到了Learned Index，对于File model，适用性更强。而且，论文的目标就是对于write heavy的场景下，实现读优化，所以论文的主要关注点在于File Learning，对于level learning 实现了，且保留配置选项。
4.4  Cost vs. Benefit Analyzer
开销和收益的分析器
由于训练一个模型是需要一定的时间开销的，但是每个SSTables文件又是由寿命限制的，且被读取的次数有限，每次优化的时间是比较小的一段。如果花一段时间去训练，结果这个模型只被用了几次而已，那就浪费且不必要了。
4.4.1 学习之前等待一小段时间
主要是对于短寿命的SStables而言，存在一些SSTables，对文件的Learned Index训练还没结束，文件就死掉了，这样训练就是浪费的，所以需要等待一段时间，这边选取的值就是训练一个文件的时间。
且根据此前文件寿命的CDF图可以知道，文件的寿命集中在短寿命和较长寿命，也就是说，等待一个小时间，仍然存活的SST寿命相对会比较长。
4.4.2 是否学习一个文件
这边使用的就是简单的一个均值估计平均的一个Cost和收益，只有当收益大于Cost的时候，才会学习一个文件。这部分不描述了，难度没有，可以用更有效的分析方式，作者这边表示可以优化。
​
<img src="../../Yemaoxin.github.io/images/2023.3.blog/Bourbon-6.png" alt="图片alt" title="图片title">

然后给出完整的Bourbon的搜索路径和结构。